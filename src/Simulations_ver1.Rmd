---
title: Simulations on Adaptive Kernel Smoothers
author: Qiuyi Wu, Cuong Pham, Xing Qiu
date: "`r format(Sys.time(), '%B %d, %Y')`"
abstract: "Optional: An abstract with font Arial 10 to describe the study."
output:
  pdf_document:
    fig_height: 6
    fig_width: 6
    fig_caption: true
---

```{r init, echo=FALSE, include=FALSE, message=FALSE}
library(knitr)
library(rmarkdown)
library(pander)
## library(captioner)
## set some global options for the R code chunks
opts_chunk$set(echo=FALSE, message=FALSE, cache=TRUE, warning=FALSE, results='hide', fig.path='results/fig', dpi=300, cache.path='.cache/')

set.seed(2569)

####  Use the following line to manually generate the report
## render("Simulations_ver1.Rmd", output_format="pdf_document")

## To produce a manual newline between tables
newline <- function(n=1) { cat(paste(rep("&nbsp;\n", n), collapse=" ")) }

## load kernel smoothing functions
source("ks.r")
## Other commonly used packages
## library(lmerTest)

```


# Introduction

## Research aims

In this study, we aim to investigate the optimal adaptive smoothing method based on Gaussian kernel smoothing.

# Method

We implemented two kernel smoothers, one for Euclidean spaces and the other for $S^1$.

... more descriptions, including the choice of window size, our "bandwidth" is actually the standard deviation of the Gaussian kernel smoother, etc.


Assume that we know the oracle noise variance and the second order derivative of the function to be estimated, the optimal bandwidth

The optimal bandwidth is
$$ b^{*} = \left( \frac{\sigma^{2}(x)}{2\sqrt{\pi} (u''(x))^2} \right)^{2/5}.  $$

Mathematical derivations of the above formula is given in a separate document.


# Simulations

## Sim1: Estimating a Quadratic Function on $[-5, 5]$

```{r sim1-true-signal, fig.cap='Optimal bandwidth computed based on our theoretical derivations.'}

## specify parameters that generates data in Sim1
N <- 501
## Note that you shouldn't use "sd" as an object; it *replaces* an
## important system function sd()!!
sd1 <- 50; var1 <- sd1^2

## an evenly-spaced grid of x defined on [-5,5]
x <- seq(-5, 5, length.out=N); dx <- 10/(N-1)
## the true function to be estimated
u <- x^4+600
## its second order derivative
D2u <- 12*x^2
## the optimal bandwidth
b = (var1/(2*sqrt(pi)*D2u^2))^(2/5)

## the fixed bandwidths
min.logb <- -1; max.logb <- -0.7; nb <- 11
logbs <- seq(min.logb, max.logb, length.out=nb)

## number of repetitions
reps <- 200

plot(x, b, type="l", ylim=c(0,5), xlab="x", ylab="Adaptive bandwidth")

```

In the first simulation, we aim to estimate the following function

$$ u(x) := x^4 + 600, \qquad x\in [-5, 5]. $$

To make our estimation easier, I decide to sample $u(x)$ on a relatively dense grid (a total number of N=`r N` evenly spaced points) on $[-5, 5]$. The observed data are the summation of $u(x_{i})$ and $i.i.d.$ normal noise $\epsilon_{j} \sim N(0, \sigma^2)$, $\sigma = `r sd1`$.

We compared the use of optimal adaptive bandwidth with fixed bandwidth (with $\log_{10} b$ ranges from `r min.logb` to `r max.logb`) in Gaussian kernel smoother.  The discrete data were smoothed by different choice of bandwidths and compared with the true underlying function $u(x)$. This simulation was repeated for $m=`r reps`$ times, and we use MSE averaged over all $x$ and repetitions to evaluate the performance of these methods.

```{r Sim1, fig.cap="Relationship between the smoothing bandwidth and mean MSE. The thick horizontal broken line on the bottom represents the mean MSE of the optimal adaptive kernel smoother; dots and thin solid curve represent the mean MSE obtained from kernel smoother with various fixed bandwidths; dotted curves represent +/- two standard errors from the mean MSEs. "}

MSEtab <- matrix(0, nrow=reps, ncol=nb+1)
colnames(MSEtab) <- c("Adaptive", paste0("logb=",logbs))

set.seed(123)
for (j in 1:reps){
  print(paste0("Repetition: ", j))
  y <- u + sd1*rnorm(N)
  yhat.adapt <- ks(x, y, bandwidth=b)
  yhat.fixed <- sapply(logbs, function(lb) ks(x,y,bandwidth=10^lb))
  Res <- sweep(cbind(yhat.adapt,yhat.fixed), 1, u)
  MSEtab[j,] <- colMeans(Res^2)
}
  
MSE.mean <- colMeans(MSEtab); MSE.se <- apply(MSEtab, 2, sd)/sqrt(reps)

plot(logbs, MSE.mean[-1], type="b", ylim=range(MSE.mean),
     xlab="log-bandwidth", ylab="Mean MSE")
## +/- 2*STDERR
lines(logbs,MSE.mean[-1]+2*MSE.se[-1], lty=3)
lines(logbs,MSE.mean[-1]-2*MSE.se[-1], lty=3)
abline(h=MSE.mean[1], lwd=2, lty=2)


```

From this figure, we see that the adaptive smoother had the smallest mean MSE, which is better than even the best fixed bandwidth smoother.

Finally, we take an arbitrary repetition (the last repetition) and show the quality of smoothing by the adaptive smoother and several choices of fixed bandwidths.

```{r Sim1.smoothing.plot, fig.cap="The true function and functions estimated by various smoothing methods. True underlying function is marked in black, adaptive smoothing in red, two choices of fixed bandwidth parameters are in green (small bandwidth, $\\log_{10} b=-1$) and blue (large bandwidth, $\\log_{10} b=-0.7$). The left panel shows all data points, and the right panel is a zoomed-in version which focuses on the right boundary. ", fig.width=12, fig.height=6}

par(mfrow=c(1,2))
plot(x, y, pch="."); lines(x,u)
lines(x, yhat.adapt, col=2)
lines(x, yhat.fixed[, 1], col=3)
lines(x, yhat.fixed[, 11], col=4)

plot(x, y, pch=1, xlim=c(4.2, 5), ylim=c(900, 1200)); lines(x,u)
lines(x, yhat.adapt, col=2)
lines(x, yhat.fixed[, 1], col=3)
lines(x, yhat.fixed[, 11], col=4)


```

As we can see from the left panel in this figure, adaptive smoothing had the best fit in the middle part of the figure; both green and blue curves *overfitted* (i.e., *under-smoothed*) the data, suggesting that a **larger** value of bandwidth should be used in that region.  However, judging from the right panel, the blue curve already started to *underfit* (over-smooth) the data at the boundary. It implies that using a larger bandwidth will only lead to worse fitting near the two boundaries. In short, the optimal adaptive smoothing achieved the best trade-off between fitting the middle (requires more smoothing) and the boundaries (requires less smoothing).

## Sim2: Estimating a Periodic Function on $S^1$

More work is needed.


```{r temp.area, eval=FALSE}

## temporary scripts

set.seed(123)
## xgrids with unequal steps
N <- 200; x <- sort(runif(N, min=-1, max=2))
## x <- seq(-1,1,.2); N <- length(x)
y <- x^2 + 3 + 0.5*rnorm(N)
## fixed bandwidth smoothing
yhat1 <- ks.fixed(x,y, .1, .3)
yhat2 <- ks.fixed(x,y, .5, 1)
yhat3 <- ks.fixed(x,y, 1,3)
## variable bandwidth smoothing
bb <- 10^seq(2,-3, length.out=N)
bb[1:5] <- Inf; bb[190:N] <- 0
## bb <- rep(Inf, N)
#bb <- seq(1, .1, length.out=N)
wins <- rep(1,N)
## yhat4 <- ks.variable(x,y, bb, wins)
yhat4 <- ks.variable(x,y, bb, wins)
## using the wrapper
yhat5 <- ks(x,y,bb)

plot(x,y)
lines(x,yhat1)
## points(x,yhat2,pch="x"); lines(x,yhat2, col=2)
lines(x,yhat3, col=3)
lines(x,yhat4, col=4)
lines(x,yhat5, col=5)



```
