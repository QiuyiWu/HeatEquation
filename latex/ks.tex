\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\title{PDE: Smoothing}
\date{June 2020}

\begin{document}

\maketitle

\section{One way of thinking}

First order Taylor expansion: 
\begin{align}
  u(x_i) \approx u(x) + \frac{\partial u}{\partial x}(x_i - x) 
\end{align}
Then 
\begin{align}
   y_i &\approx  u(x) + \frac{\partial u}{\partial x}(x_i - x) + \epsilon_i \\ 
    \hat{u}(x) &= \sum_{i=1}^n y_i w_i \\
   &= \sum_{i=1}^n \left( u(x) + \frac{\partial u}{\partial x}(x_i - x) + \epsilon_i \right) w_i \\
   &= u(x) + \sum_{i=1}^n  w_i \epsilon_i +  \frac{\partial u}{\partial x}\cdot \sum_{i=1}^n  w_i(x_i - x) \\ 
   \hat{u}(x) - u(x) &= \sum_{i=1}^n  w_i \epsilon_i +  \frac{\partial u}{\partial x}\cdot \sum_{i=1}^n  w_i(x_i - x) \\ 
     E\left[ \left(\hat{u}(x) - u(x)\right)^2 \right] &=  E\left[ \left(w_1\epsilon_1+w_2\epsilon_2+...+w_n\epsilon_n \right)^2 \right] \\&+  E\left[ \left( \frac{\partial u}{\partial x}\cdot \sum_{i=1}^n  w_i(x_i - x)\right)^2 \right] \\ 
     E\left[ \left(\hat{u}(x_i) - u(x_i)\right)^2 \right] &=  \sigma^2\sum_{i=1}^n  w_i^2  +  \left[ \frac{\partial u}{\partial x}\cdot \sum_{i=1}^n  w_i(x_i - x) \right]^2 
\end{align}


\subsection{Linear}
We let

\begin{align}
    \phi_b (x) = \frac{1}{\sqrt{2 \pi b}}\exp(\frac{-x^2}{2b})
\end{align}

where b is the band width parameter. Then we have our MSE at $x_i$

\begin{align}
   MSE_j =  \sigma^2\sum_{i=1}^n  \phi_b^2(x_j-y_i)  +  \left[ \frac{\partial u}{\partial x}\cdot \sum_{i=1}^n  \phi_b(x_j-y_i)\cdot(x_j - y_i) \right]^2 
\end{align}

Now we replace summation with integration

\begin{align}
     MSE_j =  \sigma^2 \int_\omega  \phi_b^2(x_i-y)dy  +  \left[ \frac{\partial u}{\partial x}\cdot \int_\omega  \phi_b(x_j-y_i)\cdot(x_j - y)dy \right]^2 \\
     = \sigma^2 \sqrt{2\pi \cdot b}
\end{align}


\subsection{Quadratic}

We let

\begin{align}
    \phi_b (x) = \frac{1}{\sqrt{2 \pi b}}\exp(\frac{-x^2}{2b})
\end{align}

where b is the band width parameter. Then we have our MSE at $x_i$


\begin{align}
        \left(\hat{u}(x_i) - u(x_i)\right)  &=  \sigma^2\sum_{i=1}^n  w_i^2  + \left[ \frac{\partial u}{\partial x}\cdot \sum_{i=1}^n  w_i(x_i - x) \right] +  \left[ \frac{\partial^2 u}{2\partial x^2}\cdot \sum_{i=1}^n  w_i(x_i - x)^2 \right] + \sum_{i=1}^n \epsilon_i w_i \\
        E\left[ \left(\hat{u}(x_i) - u(x_i)\right)^2 \right] &= Var\left[ \left(\hat{u}(x_i) - u(x_i)\right) \right] + (E\left[ \left(\hat{u}(x_i) - u(x_i)\right) \right])^2 \\ &=\sigma^2\sum_{i=1}^n  w_i^2  + \left[\frac{\partial u}{\partial x}\cdot \sum_{i=1}^n  w_i(x_i - x)  +   \frac{\partial^2 u}{2\partial x^2}\cdot \sum_{i=1}^n  w_i(x_i - x)^2 \right]^2 \\
   MSE_j =  \sigma^2\sum_{i=1}^n  \phi_b^2(x_j-y_i) & +  \left[ \frac{\partial u}{\partial x}\cdot \sum_{i=1}^n  \phi_b(x_j-y_i)\cdot(x_j - y_i) + \frac{\partial^2 u}{2\partial x^2}\cdot \sum_{i=1}^n  \phi_b(x_j-y_i)\cdot(x_j - y_i)^2 \right]^2
\end{align}

Now we replace summation with integration

\begin{align}
     MSE_j &=  \sigma^2 \int_\omega  \phi_b^2(x_i-y)dy  +  \left[ \frac{\partial u}{\partial x}\cdot \int_\omega  \phi_b(x_j-y)\cdot(x_j - y)dy + \frac{\partial^2 u}{2\partial x^2}\cdot \int_{\omega}  \phi_b(x_j-y)\cdot(x_j - y)^2 dy\right]^2\\
     &= \frac{\sigma^2}{2\sqrt{\pi \cdot b}}   + 0 + \left[ \frac{\partial^2 u}{2\partial x^2}\cdot \int_{\omega}  \phi_b(x_j-y)\cdot(x^2_j -2x_j\cdot y + y^2) dy\right]^2\\
     &=  \frac{\sigma^2}{2\sqrt{\pi \cdot b}}   + \left[ \frac{\partial^2 u}{2\partial x^2}\cdot \int_{\omega}  \phi_b(x_j-y)(x^2_j)dy - 2 \int_{\omega}  \phi_b(x_j-y)\cdot (x_j\cdot y)dy +  \int_{\omega}  \phi_b(x_j-y)\cdot y^2 dy\right]^2\\
     &=  \frac{\sigma^2}{2\sqrt{\pi \cdot b}}   + \left[\frac{\partial^2 u}{2\partial x^2}\cdot (x^2_j - 2x^2_j + b + x^2_j) \right]^2\\
     &=  \frac{\sigma^2}{2\sqrt{\pi \cdot b}}  + \left[\frac{\partial^2 u}{2\partial x^2}\cdot b \right]^2
\end{align}



Set $h(b) = \frac{\sigma^2}{2\sqrt{\pi}}\cdot \frac{1}{\sqrt{b}}+   \frac{1}{4}   u''^2\cdot b^2$, and take derivative, then set $h'(b) = 0$
\begin{align}
    h'(b)&= -\frac{\sigma^2}{4\sqrt{\pi}}\cdot b^{-\frac{3}{2}}+\frac{1}{2} u''^\cdot b = 0\\
    b &=\left(\frac{\sigma^2}{2\sqrt{\pi} u''^2}\right)^{\frac{2}{5}} 
\end{align}











\section{Another way of thinking}

Gaussian Kernel: 

$$w_{ij}(x_j, g)  = \exp[- \frac{(x_i - x_j)^2}{2g^2}]$$

We have 

$$MSE(x_j, g) = E[\hat{\mu}(x_j) - \mu(x_j)]^2$$

We will need to minimize 

$$MSE(g) = \sum_{j=1}^n MSE(x_j, g)$$

We have 

$$\hat{\mu}(x_j, i) = \mu(x_j) + \sum_{i = 1}^{n} w_{ij}(\mu'(x_j)(x_i-x_j) + \epsilon_i)  $$

Where $\epsilon_i$ follows $N(0, \sigma^2)$

Hence 

$$MSE(x_j,g) = E[\sum_{i = 1}^{n} w_{ij}(\mu'(x_j)(x_i-x_j) + \epsilon_i) ]^2$$
$$=Var(\sum_{i = 1}^{n} w_{ij}(\mu'(x_j)(x_i-x_j) + \epsilon_i)) + (E[\sum_{i = 1}^{n} w_{ij}(\mu'(x_j)(x_i-x_j) + \epsilon_i) ])^2$$
$$=\sigma^2\sum_{i=1}^n w_{ij}^2 + [\sum_{i=1}^n w_{ij}\mu'(x_j)(x_i-x_j)]^2$$



\section{Question}



\begin{align*}
    Y_i &= g(x_i)+\epsilon_i\\ 
    MSE &= \sum_{i=1}^N(\hat{Y}_i- Y_i)^2 = \sum_{i=1}^N(\hat{Y}_i- g(x_i))^2\\ 
    MISE &= \int_1^5[\hat{g}(x) - g(x)]^2dx =\int_1^5[\hat{Y}_i - g(x)]^2dx =  \sum_{i=1}^N[\hat{Y}_i - g(x)]^2\cdot dx
\end{align*}












\end{document}







\end{document}
